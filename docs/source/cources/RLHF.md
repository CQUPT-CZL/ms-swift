## **人类对齐**

人类对齐训练是base模型转变为chat模型的关键步骤，一般来说chat模型具有模型特定的prompt模板，并且可以回答出人类想要的答案，这个过程就是人类对齐。

人类对齐数据集一般**一个问题有多个回答**（及这些回答的好坏排序），之后根据回答的好坏促使模型选择较好的回答，以此达到“教模型如何回答人们想要的答案”的目标。

人类对齐训练有多种方式，从最早的RM+PPO训练，到后来的DPO训练，训练方式变得越来越简单。

人类对齐数据集的数据量从几十万到几个亿不等。