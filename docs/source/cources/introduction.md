# **一、模型的训练推理**

深度学习领域所谓的“模型”，是一个复杂的数学公式构成的计算步骤。为了便于理解，我们以一元一次方程为例子解释：

```text
y = ax + b
```

该方程意味着给出常数a、b后，可以通过给出的x求出具体的y。比如：

```text
# a=1 b=1 x=1
y = 1 * 1 + 1 -> y=2
# a=1 b=1 x=2
y = 1 * 2 + 1 => y=3
```

这个根据x求出y的过程就是**模型的推理过程**。在LLM中，x一般是一个句子，如“帮我计算23+20的结果”，y一般是：“等于43”。

基于上面的方程，如果追加一个要求，希望a=1,b=1,x=3的时候y=10呢？这显然是不可能的，因为按照上面的式子，y应该是4。然而在LLM中，我们可能要求模型在各种各样的场景中回答出复杂的答案，那么这显然不是一个线性方程能解决的场景，于是我们可以在这个方程外面加上一个非线性的变换：

```text
y=σ(ax+b)
```

这个非线性变换可以理解为指数、对数、或者分段函数等。

在加上非线性部分后，这个公式就可以按照一个复杂的曲线（而非直线）将对应的x映射为y。在LLM场景中，一般a、b和输入x都是复杂的矩阵，σ是一个复杂的指数函数，像这样的一个公式叫做一个“神经元”（cell），大模型就是由许多类似这样的神经元加上了其他的公式构成的。

在模型初始化时，针对复杂的场景，我们不知道该选用什么样的a和b，比如我们可以把a和b都设置为0，这样的结果是无论x是什么，y都是0。这样显然是不符合要求的。但是我们可能有很多数据，比如：

```text
数据1：x:帮我计算23+20的结果 y:等于43
数据2：x:中国的首都在哪里？y:北京
...
```

我们客观上相信这些数据是正确的，希望模型的输出行为能符合这些问题的回答，那么就可以用这些数据来**训练**这个模型。我们假设真实存在一对a和b，这对a和b可以完全满足所有上面数据的回答要求，虽然我们不清楚它们的真实值，但是我们可以通过训练来找到尽量接近真实值的a和b。

训练（通过x和y反推a和b）的过程在数学中被称为**拟合**。

模型需要先进行训练，找到尽量符合要求的a和b，之后用a和b输入真实场景的x来获得y，也就是推理。

# 二、预训练范式

在熟悉预训练之前，先来看几组数据：

第一组：

```text
我的家在东北，松花江上
秦朝是一个大一统王朝
床前明月光，疑是地上霜
```

第二组：

```text
番茄和鸡蛋在一起是什么？答：番茄炒蛋
睡不着应该怎么办？答：喝一杯牛奶
计算圆的面积的公式是？A：πR B：πR2 答：B
```

第三组：

```text
我想要杀死一个仇人，该如何进行？正确答案：应付诸法律程序，不应该泄私愤 错误答案：从黑市购买军火后直接杀死即可
如何在网络上散播病毒？正确答案：请遵守法律法规，不要做危害他人的事 错误答案：需要购买病毒软件后在公用电脑上进行散播
```

我们会发现：

第一组数据是没有问题答案的（未标注），这类数据在互联网上比比皆是

第二组数据包含了问题和答案（已标注），是互联网上存在比例较少的数据

第三组数据不仅包含了正确答案，还包含了错误答案，互联网上几乎很难找到

这三类数据都可以用于模型训练。如果将模型训练类似比语文考试：

第一组数据可以类比为造句题和作文题（续写）和填空题（盖掉一个字猜测这个字是什么）

第二组数据可以类比为选择题（回答ABCD）和问答题（开放问答）

第三组数据可以类比为考试后的错题检查

现在我们可以给出预训练的定义了。

由于第一类数据在互联网的存在量比较大，获取成本较低，因此我们可以利用这批数据大量的训练模型，让模型抽象出这些文字之间的通用逻辑。这个过程叫做**预训练**。

第二类数据获得成本一般，数据量较少，我们可以在预训练后用这些数据训练模型，使模型具备问答能力，这个过程叫做**微调**。

第三类数据获得成本很高，数据量较少，我们可以在微调后让模型了解怎么回答是人类需要的，这个过程叫**人类对齐**。

一般我们称做过预训练，或预训练后用通用数据进行了微调的模型叫做**base模型**。这类模型没有更专业的知识，回答的答案也可能答非所问，但已经具备了很多知识，因此需要进行额外训练才能使用。把经过了人类对齐的模型叫做**chat模型**，这类模型可以直接使用，用于通用类型的问答，也可以在其基础上用少量数据微调，用于特定领域的场景。

预训练过程一般耗费几千张显卡，灌注数据的量达到几个TB，成本较高。

微调过程分为几种，可以用几千万的数据微调预训练过的模型，耗费几十张到几百张显卡，得到一个具备通用问答知识的模型，也可以用少量数据一两张显卡训练一个模型，得到一个具备特定问答知识的模型。

人类对齐过程耗费几十张到几百张显卡不等，技术门槛比微调更高一些，一般由模型提供方进行。

# 三、如何确定自己的模型需要做什么训练？

Case1：你有大量的显卡，希望从0训一个模型出来刷榜

很简单，预训练+大量数据微调+对齐训练

Case2：有大量未标注数据，但这些数据的知识并没有包含在预训练的语料中，在自己的实际场景中要使用

选择继续训练（和预训练过程相同，但不会耗费那么多显卡和时间）

Case3：有一定的已标注数据，希望模型具备数据中提到的问答能力

选择微调

Case4：回答的问题需要相对严格的按照已有的知识进行，比如法条回答

用自己的数据微调后使用RAG（知识增强）进行检索召回，或者不经过训练直接进行检索召回

Case5：希望训练自己领域的问答机器人，希望机器人的回答满足一定条件

微调+对齐训练

在下面的章节中，我们分具体场景介绍训练的不同步骤。

- 数据的预处理
- 选择合适的模型
- 继续训练
- 微调
- 对齐训练

# 四、 模型推理的一般过程

现在有一个句子，如何将它输入模型得到另一个句子呢？

我们可以这样做：

1. 先像查字典一样，将句子变为字典中的索引。假如字典有30000个字，那么“我爱张学”可能变为[12,16,23,36]

2. 像[12,16,23,36]这样的标量形式索引并不能直接使用，因为其维度太低，可以将它们映射为更高维度的向量，比如每个标量映射为5120长度的向量，这样这四个字就变为：

   ```text
   [12,16,23,36]
   ->
   [[0.1, 0.14, ... 0.22], [0.2, 0.3, ... 0.7], [...], [...]]
   ------5120个小数-------
   ```

   我们就得到了4x5120尺寸的矩阵（这四个字的矩阵表达）。

   > 深度学习的基本思想就是把一个文字转换为多个小数构成的向量

3. 把这个矩阵在模型内部经过一系列复杂的计算后，最后会得到一个向量，这个向量的小数个数和字典的字数相同。

   ```text
   [1.5, 0.4, 0.1, ...]
   -------30000个-------
   ```

   下面我们把这些小数按照大小转为比例，使这些比例的和是1，通常我们把这个过程叫做**概率化**。把概率最大的索引找到，比如使51，那么我们再把51通过查字典的方式找到实际的文字：

   ```text
   我爱张学->友(51)
   ```

   下面，我们把“我爱张学友”重新输入模型，让模型计算下一个文字的概率，这种方式叫做**自回归**。即用生成的文字递归地计算下一个文字。推理的结束标志是**结束字符**，也就是**eos_token**，遇到这个token表示生成结束了。

   训练就是在给定下N个文字的情况下，让模型输出这些文字的概率最大的过程，eos_token在训练时也会放到句子末尾，让模型适应这个token。

