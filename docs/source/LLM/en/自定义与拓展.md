# 自定义与拓展
## 目录
- [自定义数据集](#自定义数据集)
- [自定义模型](#自定义模型)
- [自定义对话模板](#自定义对话模板)

## 自定义数据集
我们支持两种**自定义数据集**的方法。

1. 【推荐】**命令行参数**的形式：**更加方便支持本地自定义数据集**。
2. **注册数据集**的方式：更加灵活，可以对swift**进一步拓展和开发**，但需要一定的编程门槛。方法一在实现上借助了方法二。

### 📌 【推荐】命令行参数的形式
你需要在sft.sh脚本中额外指定：

```shell
--custom_train_dataset_path xxx.jsonl \
--custom_val_dataset_path yyy.jsonl \
```

对应的sh案例脚本可以查看[这里](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/scripts/tongyi_finance_14b_chat_int4/qlora/sft.sh)。

1. `--custom_train_dataset_path`：默认值为`[]`，表示不使用自定义数据集。你可以像如下形式进行指定：`--custom_train_dataset_path alpaca.csv`或者指定多个训练数据集`--custom_train_dataset_path alpaca.csv chatml.jsonl swift.jsonl`，脚本会进行自动的预处理和拼接。

   > 可以通过公开数据集和自定义数据集结合的方式进行训练：`--dataset blossom-math-zh --custom_train_dataset_path custom_math.jsonl`。

2. `--custom_val_dataset_path`：默认值为`[]`，表示不使用自定义验证数据集。如果你指定了`custom_train_dataset_path`，则自定义数据集的验证集将按照命令行参数`dataset_test_ratio`进行切割。

脚本支持的文件格式包含`csv`，`json`，`jsonl`格式。你需要将传入的文件符合以下数据集格式。csv格式的文件只支持指令微调，即没有history的情况。json, jsonl格式的文件支持system, history。

**格式1：**

Pre-Training

```csv
response
11111
aaaaa
AAAAA
```

```jsonl
{"response": "11111"}
{"response": "aaaaa"}
{"response": "AAAAA"}
```

Single-Round Dialogue

```csv
query,response
11111,22222
aaaaa,bbbbb
AAAAA,BBBBB
```

```jsonl
{"query": "11111", "response": "22222"}
{"query": "aaaaa", "response": "bbbbb"}
{"query": "AAAAA", "response": "BBBBB"}
```

Multi-Round Dialogue

```jsonl
{"query": "55555", "response": "66666"}
{"query": "eeeee", "response": "fffff", "history": []}
{"query": "EEEEE", "response": "FFFFF", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}
```

```json
[{"query": "55555", "response": "66666"},
{"query": "eeeee", "response": "fffff", "history": []},
{"query": "EEEEE", "response": "FFFFF", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}]
```

**格式2：**

```jsonl
{"conversations": [{"from": "user", "value": "11111"}, {"from": "assistant", "value": "22222"}]}
{"conversations": [{"from": "user", "value": "aaaaa"}, {"from": "assistant", "value": "bbbbb"}, {"from": "user", "value": "ccccc"}, {"from": "assistant", "value": "ddddd"}]}
{"conversations": [{"from": "user", "value": "AAAAA"}, {"from": "assistant", "value": "BBBBB"}, {"from": "user", "value": "CCCCC"}, {"from": "assistant", "value": "DDDDD"}]}
```

**格式3：**

```jsonl
{"messages": [{"role": "user", "content": "11111"}, {"role": "assistant",, "content": "22222"}]}
{"messages": [{"role": "user", "content": "aaaaa"}, {"role": "assistant", "content": "bbbbb"}, {"role": "user", "content": "ccccc"}, {"role": "assistant", "content": "ddddd"}]}
{"messages": [{"role": "user", "content": "AAAAA"}, {"role": "assistant", "content": "BBBBB"}, {"role": "user", "content": "CCCCC"}, {"role": "assistant", "content": "DDDDD"}]}
```

**格式4：**

```csv
instruction,input,output
11111,22222,33333
aaaaa,bbbbb,ccccc
AAAAA,BBBBB,CCCCC
```

**强化学习（DPO）**

```jsonl
{"query": "11111", "response": "22222", "rejected_response": "33333"}
{"query": "aaaaa", "response": "bbbbb", "rejected_response": "ccccc"}
{"query": "AAAAA", "response": "BBBBB", "rejected_response": "CCCCC"}
```

### 注册数据集的方式

以下是一个**注册数据集**的案例。完整的py文件可以查看[custom.py](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/custom.py)，sh脚本可以查看[custom](https://github.com/modelscope/swift/tree/main/examples/pytorch/llm/scripts/custom)。

```python
from typing import Optional, Tuple

from datasets import Dataset as HfDataset
from modelscope import MsDataset

from swift.llm import get_dataset, register_dataset
from swift.utils import get_logger

logger = get_logger()


class CustomDatasetName:
    stsb_en = 'stsb-en'

def _preprocess_stsb(dataset: HfDataset) -> HfDataset:
    prompt = """Task: Based on the given two sentences, provide a similarity score between 0.0 and 5.0.
Sentence 1: {text1}
Sentence 2: {text2}
Similarity score: """
    query = []
    response = []
    for d in dataset:
        query.append(prompt.format(text1=d['text1'], text2=d['text2']))
        response.append(f"{d['label']:.1f}")
    return HfDataset.from_dict({'query': query, 'response': response})


@register_dataset(
    CustomDatasetName.stsb_en, 'huangjintao/stsb', task='text-generation')
def get_stsb_dataset(dataset_id_or_path: str,
                     **kwargs) -> Tuple[HfDataset, Optional[HfDataset]]:
    dataset_dict = MsDataset.load(dataset_id_or_path)
    train_dataset = dataset_dict['train'].to_hf_dataset()
    val_dataset = dataset_dict['validation'].to_hf_dataset()
    return tuple(
        _preprocess_stsb(dataset) for dataset in [train_dataset, val_dataset])


if __name__ == '__main__':
    # test dataset
    train_dataset, val_dataset = get_dataset([CustomDatasetName.stsb_en],
                                             check_dataset_strategy='warning')
    print(f'train_dataset: {train_dataset}')
    print(f'val_dataset: {val_dataset}')
```

`register_dataset`会在`DATASET_MAPPING`中注册数据集，该函数的参数含义如下：

- `dataset_name`：必填项，表示数据集的名字，也是数据集的唯一id。
- `dataset_id_or_path`：必填项。表示数据集在ModelScope Hub上的`dataset_id`或者本地的`dataset_dir`。
- `get_function`：默认值为`None`。获取数据集的函数。如果传入None，则使用修饰器方案进行数据集注册。如果传入一个函数，则使用正常方案进行注册。
  > `get_function`需要返回`HfDataset`或`Tuple[HfDataset, Optional[HfDataset]]`。如果只返回一个数据集，则该数据集为train_dataset，数据集处理函数会切分一部分的数据集作为val_dataset（根据命令行参数`dataset_test_ratio`）；如果返回两个数据集，则分别作为train_dataset和val_dataset。我们支持使用多个数据集进行微调`get_dataset(['dataset1', 'dataset2'])`。我们会将各个子数据集的训练集和验证集部分分别进行拼接，最终返回合并后的训练集和验证集。

  > 函数返回的`HfDataset`需要符合一定的规范。如果你要进行**预训