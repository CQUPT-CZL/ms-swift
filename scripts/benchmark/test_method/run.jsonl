["--sft_type", "lora", "--model_type", "qwen-7b-chat"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat-int4"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat-int8"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--lora_target_modules", "ALL"]
["--sft_type", "lora", "--model_type", "qwen-14b-chat"]
["--sft_type", "lora", "--model_type", "qwen-1_8b-chat"]
["--sft_type", "full", "--model_type", "qwen-7b-chat"]
["--sft_type", "lora", "--model_type", "qwen-7b"]
["--sft_type", "lora", "--model_type", "chatglm2-6b"]
["--sft_type", "lora", "--model_type", "chatglm3-6b"]
["--sft_type", "lora", "--model_type", "baichuan2-7b-chat"]
["--sft_type", "lora", "--model_type", "openbuddy-mistral-7b-chat"]
["--sft_type", "lora", "--model_type", "openbuddy-zephyr-7b-chat"]
["--sft_type", "lora", "--model_type", "yi-6b"]
["--sft_type", "full", "--model_type", "qwen-7b-chat", "--freeze_parameters", "0.2"]
["--sft_type", "full", "--model_type", "qwen-7b-chat", "--freeze_parameters", "0.5"]
["--sft_type", "full", "--model_type", "qwen-7b-chat", "--freeze_parameters", "0.8"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--quantization_bit", "4"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--lora_rank", "2"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--lora_rank", "4"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--lora_rank", "32"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--lora_rank", "64"]
["--sft_type", "lora", "--model_type", "qwen-7b-chat", "--gradient_checkpointing", "false"]
[]
